#aesthetics outside aes
ggplot(data=diamonds,aes(x=clarity))+
geom_bar(fill='gold')
ggplot(data=diamonds,aes(x=clarity))+
geom_bar(aes(fill='gold')) #should be outside aes!
#fill/color
ggplot(data=diamonds,aes(x=clarity,color=cut))+
geom_bar()
ggplot(data=mtcars,aes(factor(cyl),fill=factor(cyl)))+
geom_bar(color='black')
ggplot(data=mtcars,aes(factor(cyl),color=factor(cyl)))+
geom_bar()
help(points)
#other color systems
(plottemp <- ggplot(data=diamonds,aes(x=clarity,fill=cut))+
geom_bar())
plottemp + scale_fill_brewer(palette='Set2') #in-built
plottemp + scale_fill_grey(name = "cut of\ndiamonds")
plottemp + scale_fill_grey(name = "cut of\ndiamonds") + theme_bw()
# ggsci ####
plottemp+scale_fill_lancet()
plottemp+scale_fill_jama()
plottemp+scale_fill_startrek()
#save ggplots
ggsave('ggtestplot.png',width=20,height=20,
units='cm',dpi=150)
#other geoms
ggplot(data=mtcars,aes(x = wt,y = mpg))+
geom_point() #default 1.5 IQR
ggplot(mtcars,aes(x = factor(gear),y = wt))+
geom_boxplot()
ggplot(mtcars,aes(x = factor(gear),y = wt))+
geom_boxplot(coef=3)
ggplot(mtcars,aes(x = factor(gear),y = wt,fill=factor(cyl)))+
geom_boxplot(coef=3)
ggplot(mtcars,aes(x = factor(gear),y = wt))+
geom_boxplot(coef=3)+
geom_point()
ggplot(mtcars,aes(x = factor(gear),y = wt))+
geom_boxplot(coef=3)+
geom_point(position = position_jitter(width = .1))
ggplot(mtcars,aes(x = factor(gear),y = wt))+
geom_boxplot(coef=3)+
geom_dotplot(alpha=.7,
binaxis = 'y',stackdir = 'center',
stackratio = .7,dotsize = .6)
#aesthetics again (finetuning)
ggplot(data=mtcars,aes(wt, mpg,color=qsec))+
geom_point(size=4) #outside aes!
ggplot(data=mtcars,aes(wt, mpg,color=qsec, size=carb))+
geom_point()
ggplot(data=mtcars,aes(wt, mpg,color=qsec, size=carb))+
scale_color_gradient(low='darkred',high='blue')+
geom_point()
ggplot(data=mtcars,aes(wt, mpg,color=qsec, size=carb))+
scale_color_gradient2(low='red',high='yellow',
mid='blue',
limits=c(13,23),midpoint=18)+
geom_point()
# use different aesthetic mappings
ggplot(data=mtcars,
aes(wt, mpg,size=qsec, shape=factor(cyl)))+
geom_point()
ggplot(data=mtcars,aes(carb, mpg,color=qsec, size=wt))+
geom_point(shape=2)
#location, location,position
p<-ggplot(data=diamonds,aes(clarity,fill=cut))
p+geom_bar(position="stack")
p+geom_bar(position="dodge")
p+geom_bar(position="fill")
p+geom_bar(position="fill")+
scale_y_continuous('Frequency (%)',
breaks=seq(0,1,.2),
labels=seq(0,100,20))
p+geom_bar(position="identity")
p+geom_bar(position="identity",alpha=.5)
ggplot(data=diamonds,aes(clarity,color=cut, group=cut))+
geom_freqpoly(stat='count',position="identity",lwd=1.5)+
geom_point(stat='count',size=5)
#layer/order / computed geoms
ggplot(data=mtcars,aes(wt, mpg))+
geom_point(size=4)+
geom_smooth(size=3)
ggplot(data=mtcars,aes(wt, mpg))+
geom_smooth(size=3)+
geom_point(size=4)
ggplot(data=mtcars,aes(wt, mpg))+
geom_smooth(size=3,color='red')+
geom_smooth(method='lm',size=3)+
geom_point(size=4)
ggplot(data=mtcars,aes(wt, mpg,color=factor(cyl)))+
geom_point(size=4)+
geom_smooth(method='lm',size=1)
ggplot(data=mtcars,aes(wt, mpg,color=factor(cyl),
shape=factor(am)))+
geom_point(size=2)+
geom_smooth(method='lm',size=1,se=F)
#? lm for all?
ggplot(data=mtcars,aes(wt, mpg))+
geom_smooth(size=1,color='black',fill='yellow')+
geom_point(size=3,aes(color=factor(cyl),shape=factor(am))) #aes for geom only
# facet_wrap / facet_grid
(p.tmp <- ggplot(mtcars, aes(mpg, wt)) + geom_point())
p.tmp + facet_wrap(~cyl)
p.tmp + facet_wrap(~cyl, ncol=2)
p.tmp + facet_grid(gear~cyl,labeller=label_both,margins='gear')
p.tmp + geom_smooth()+
facet_grid(gear~cyl, labeller=label_both,margins=T)
View(Spinat1)
install.packages("keras")
library(keras)
library(keras)
model.1 keras_model_sequential()
model.1 <- keras_model_sequential()
install_tensorflow()
install.packages("tensorflow")
library(keras)
model.1 <- keras_model_sequential()
library(tensorflow)
model.1 <- keras_model_sequential()
model1 <- keras_model_sequential()
model1 <- keras_model_sequential()
library(keras)
model1 <- keras_model_sequential()
install.packages("keras")
library(keras)
model1 <- keras_model_sequential()
install_tensorflow()
library(tensorflow)
install_tensorflow()
library(keras)
model1 <- keras_model_sequential()
model1 %>%
# wir fügen einen Layer (densley connected) mit 64 units an
layer_dense(units = 64, activation = "relu") %>%
# und noch einen Layer mit 64 units
layer_dense(units = 64, activation = "relu") %>%
# und einen Output-softmax
layer_dense(units = 10, activation = "softmax")
model.1 <- keras_model_sequential()
model.1 %>%
# wir fügen einen Layer (densley connected) mit 64 units an
layer_dense(units = 64, activation = "relu") %>%
# und noch einen Layer mit 64 units
layer_dense(units = 64, activation = "relu") %>%
# und einen Output-softmax
layer_dense(units = 10, activation = "softmax")
data.1 <- matrix(
rnorm(1000 * 32),
nrow = 1000,
ncol = 32
)
labels.1 <- matrix(rnorm(1000, 10),
nrow = 1000,
ncol = 10)
labels.1 <- matrix(rnorm(1000, 10),
nrow = 1000,
ncol = 10)
data.1 <-
matrix(
rnorm(1000 * 32),
nrow = 1000,
ncol = 32
)
data.1 <-matrix(
rnorm(1000 * 32),
nrow = 1000,
ncol = 32
)
data.1 <-
matrix(
rnorm(1000 * 32),
nrow = 1000,
ncol = 32
)
data.1 <-
matrix(
rnorm(1000 * 32),
nrow = 1000,
ncol = 32
)
labels.1 <-
matrix(
rnorm(1000, 10),
nrow = 1000,
ncol = 10)
val.dat <-
matrix(
rnorm(1000, 32),
nrow = 100,
ncol = 32
)
val_data <- matrix(rnorm(1000 * 32), nrow = 100, ncol = 32)
val_labels <- matrix(rnorm(100 * 10), nrow = 100, ncol = 10)
val_data <-
matrix(
rnorm(1000 * 32),
nrow = 100,
ncol = 32)
val_labels <-
matrix(
rnorm(100 * 10),
nrow = 100,
ncol = 10)
model.1
model.1 %>%
fit(
data.1,
labels.1,
epochs = 10,
batch_size = 32,
validation_data = list( val_data,
val_labels)
)
model %>% compile(
optimizer = 'adam',
loss = 'mse',           # mean squared error
metrics = list('mae')   # mean absolute error
)
model %>% compile(
optimizer = 'adam',
loss = 'categorical_crossentropy',
metrics = list('accuracy')
)
# Create a sigmoid layer:
layer_dense(units = 64, activation ='sigmoid')
# A linear layer with L1 regularization of factor 0.01 applied to the kernel matrix:
layer_dense(units = 64, kernel_regularizer = regularizer_l1(0.01))
# A linear layer with L2 regularization of factor 0.01 applied to the bias vector:
layer_dense(units = 64, bias_regularizer = regularizer_l2(0.01))
# A linear layer with a kernel initialized to a random orthogonal matrix:
layer_dense(units = 64, kernel_initializer = 'orthogonal')
# A linear layer with a bias vector initialized to 2.0:
layer_dense(units = 64, bias_initializer = initializer_constant(2.0))
model %>% compile(
optimizer = 'adam',
loss = 'categorical_crossentropy',
metrics = list('accuracy')
)
model %>% compile(
optimizer = 'adam',
loss = 'mse',           # mean squared error
metrics = list('mae')   # mean absolute error
)
library(keras)
model.1 <- keras_model_sequential()
model.1 %>%
# wir fügen einen Layer (densley connected) mit 64 units an
layer_dense(units = 64, activation = "relu") %>%
# und noch einen Layer mit 64 units
layer_dense(units = 64, activation = "relu") %>%
# und einen Output-softmax
layer_dense(units = 10, activation = "softmax")
data.1 <-
matrix(
rnorm(1000 * 32),
nrow = 1000,
ncol = 32
)
labels.1 <-
matrix(
rnorm(1000, 10),
nrow = 1000,
ncol = 10)
val_data <-
matrix(
rnorm(1000 * 32),
nrow = 100,
ncol = 32)
val_labels <-
matrix(
rnorm(100 * 10),
nrow = 100,
ncol = 10)
model.1 %>%
fit(
data.1,
labels.1,
epochs = 10,
batch_size = 32,
validation_data = list( val_data,
val_labels)
)
# use prior analysis as source
source('HSA.R')
library(readr)
# load the complete dataset
# use prior analysis as source
source('HSA.R')
library(readr)
# load the complete dataset
library(readxl)
HSA_Arno <- read_excel("Bachelor/Beispielauswertungen/HSA_Assay/HSA_Arno.xlsx",
sheet = "Tabelle2", col_types = c("skip",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric"))
View(HSA_Arno)
plot(HSA_Arno)
HSA_Arno <- read_excel("Bachelor/Beispielauswertungen/HSA_Assay/HSA_Arno.xlsx",
sheet = "Tabelle2", col_types = c("char",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric"))
HSA_Arno <- read_excel("Bachelor/Beispielauswertungen/HSA_Assay/HSA_Arno.xlsx",
sheet = "Tabelle2", col_types = c("char",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric"))
HSA_Arno <- read_excel("Bachelor/Beispielauswertungen/HSA_Assay/HSA_Arno.xlsx",
sheet = "Tabelle2", col_types = c("character",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric"))
character()
HSA_Arno <- read_excel("Bachelor/Beispielauswertungen/HSA_Assay/HSA_Arno.xlsx",
sheet = "Tabelle2")
HSA_Arno <- read_excel("Bachelor/Beispielauswertungen/HSA_Assay/HSA_Arno.xlsx",
sheet = "Tabelle2")
View(HSA_Arno)
as.array(HSA_Arno)
HSA_Arno <- read_excel("Bachelor/Beispielauswertungen/HSA_Assay/HSA_Arno.xlsx",
sheet = "Tabelle2", skip = 1)
View(HSA_Arno)
as.array(HSA_Arno)
HSA_Arno <- read_excel("Bachelor/Beispielauswertungen/HSA_Assay/HSA_Arno.xlsx",
sheet = "Tabelle2")
View(HSA_Arno)
as.array(HSA_Arno)
p <- ggplot(mtcars, aes(wt, mpg))
p + stat_identity()
p <- ggplot(mtcars, aes(wt, mpg))
library(tidyverse)
p <- ggplot(mtcars, aes(wt, mpg))
p + stat_identity()
install.packages("units")
setwd()
setwd("Bachelor/Biotech/")
library(devtools)
use_testthat()
source('~/Bachelor/Beispielauswertungen/HSA_Assay/concentrations_visualisation.R', echo=TRUE)
# use prior analysis as source
source('~/Bachelor/Beispielauswertungen/HSA_Assay/')
# use prior analysis as source
source('/Users/lovisrieger/Bachelor/Beispielauswertungen/HSA_Assay/HSA.R')
# use prior analysis as source
source('~/Bachelor/Beispielauswertungen/HSA_Assay/HSA.R')
str(HSA.A)
# use prior analysis as source
source('~/Bachelor/Beispielauswertungen/HSA_Assay/HSA.R')
packages <- readRDS("~/Bachelor/Biotech/packages.rds")
View(packages)
View(packages)
l
ls.diag()
list()
check()
check()
load_all()
document()
source('~/Bachelor/Biotech/R/Eadie_Hofstee.R', echo=TRUE)
document()
check()
source('~/Bachelor/Biotech/R/dose_response_plot.R', echo=TRUE)
document()
document()
check()
document()
check()
source('~/Bachelor/Biotech/R/conc_4PL.R', echo=TRUE)
#' Compute the concentration of an competitive ELISA based on the 4-Parameter-logistic function
#'
#' @param std.conc the concentration of the calibrators
#' @param std.resp the measured absorbance of the calibrators
#' @param mes.resp the measured absorbance of the samples of unknown concentration
#'
#' @return the model-fit and the concentration of the samples
#' @export
#'
conc.4PL <- function (std.conc,
std.resp,
mes.resp) {
fit <-
dr4pl::dr4pl( std.conc~std.resp )
conc <-
fit$parameters[1] + ((fit$parameters[4] - fit$parameters[1])/(1 + (abs.P/fit$parameters[2])^fit$parameters[3]))
return(
list(
fit,
conc
)
)
}
source('~/Bachelor/Biotech/R/conc_4PL.R', echo=TRUE)
source('~/Bachelor/Biotech/R/conc_4PL.R', echo=TRUE)
#' Compute the concentration of an competitive ELISA based on the 4-Parameter-logistic function
#'
#' @param std.conc the concentration of the calibrators
#' @param std.resp the measured absorbance of the calibrators
#' @param mes.resp the measured absorbance of the samples of unknown concentration
#'
#' @return the model-fit and the concentration of the samples
#' @export
#'
conc.4PL <- function (std.conc,
std.resp,
mes.resp,
) {
fit <-
dr4pl::dr4pl( std.conc~std.resp )
conc <-
fit$parameters[1] + ((fit$parameters[4] - fit$parameters[1])/(1 + (mes.resp/fit$parameters[2])^fit$parameters[3]))
return(
list(
fit,
conc
)
)
}
#' Compute the concentration of an competitive ELISA based on the 4-Parameter-logistic function
#'
#' @param std.conc the concentration of the calibrators
#' @param std.resp the measured absorbance of the calibrators
#' @param mes.resp the measured absorbance of the samples of unknown concentration
#'
#' @return the model-fit and the concentration of the samples
#' @export
#'
conc.4PL <- function (std.conc,
std.resp,
mes.resp,
) {
fit <-
dr4pl::dr4pl( std.conc~std.resp )
conc <-
fit$parameters[1] + ((fit$parameters[4] - fit$parameters[1])/(1 + (mes.resp/fit$parameters[2])^fit$parameters[3]))
return(
list(
fit,
conc
)
)
}
conc <-
fit$parameters[1] + ((fit$parameters[4] - fit$parameters[1])/(1 + (mes.resp/fit$parameters[2])^fit$parameters[3]))
#' Compute the concentration of an competitive ELISA based on the 4-Parameter-logistic function
#'
#' @param std.conc the concentration of the calibrators
#' @param std.resp the measured absorbance of the calibrators
#' @param mes.resp the measured absorbance of the samples of unknown concentration
#'
#' @return the model-fit and the concentration of the samples
#' @export
#'
conc.4PL <- function (std.conc,
std.resp,
mes.resp) {
fit <-
dr4pl::dr4pl( std.conc~std.resp )
conc <-
fit$parameters[1] + ((fit$parameters[4] - fit$parameters[1])/(1 + (mes.resp/fit$parameters[2])^fit$parameters[3]))
return(
list(
fit,
conc
)
)
}
document()
check()
Eadie_Hofstee(vel = 1, sub = 1, printfigure = T)
check()
document()
check()
#'
#' @examples
#' # simulate values
#' sub <-seq(1,20,1)
#' vel <-((runif(1,14.7,15)*sub)/(runif(1,2.5,3)+sub))+rnorm(20,0,.3)
#' # plot them
#' Eadie_Hofstee(vel = vel, sub = sub)
#'
#'
#'
Eadie_Hofstee <- function(vel, sub, titleEDH = "Eadie-Hostee-Plot",
xlable = "vel/sub", ylable = "sub",
printfigure = TRUE ){
EHPlot <-   ggplot2::ggplot(mapping = ggplot2::aes(
x = vel/sub,
y = vel)
)+
ggplot2::geom_point()+
ggplot2::geom_smooth(method = "lm",
fullrange = TRUE)+
ggplot2::scale_x_continuous(expand=c(0,0), limits=c(0, base::max(vel/sub))) +
ggplot2::scale_y_continuous(expand=c(0,0), limits=c(0, base::max(vel)+20))+
ggplot2::ggtitle(titleEDH)+
ggplot2::xlab(xlable)+
ggplot2::ylab(ylable)
EHModel <- stats::lm(vel/sub~vel)
EHSummary <- base::summary(EHModel)
return(list(EHPlot=EHPlot, EHmodel=EHModel, EHSummary))
}
document()
check()
document()
check()
checkCRAN()
