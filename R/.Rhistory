}  else {
x    <- min(x, sqrt((N - m)/k) - 1e-10)
#
# Log of Gould's equation B:
LnQN <- k * log(k) + (N - k) * log(N - k) - N * log(N)
#
# Gould's equation D:
R1   <- exp((x^2 - 1)/2) * erfc(x/sqrt(2))
#
# Gould's equation A' solved for R w/ Lambda substitution:
R2   <- exp( (LnQN - 0.5 * (N - k) * log((N-m-k*x^2)/(N-m-k)) )/k )
#
# Equate the two R equations:
R1d  <- x * R1 - sqrt(2/pi/exp(1))
R2d  <- x * (N - k)/(N - m - k * x^2) * R2
#
# Update x:
oldx <- x
x    <- oldx - (R1 - R2)/(R1d - R2d)
#
# Loop until convergence:
while (abs(x - oldx) >= N * 2e-16){
R1   <- exp((x^2 - 1)/2) * erfc(x/sqrt(2))
R2   <- exp( (LnQN - 0.5 * (N - k) * log((N-m-k*x^2)/(N-m-k)) )/k )
R1d  <- x * R1 - sqrt(2/pi/exp(1))
R2d  <- x * (N - k)/(N - m - k * x^2) * R2
oldx <- x
x    <- oldx - (R1 - R2)/(R1d - R2d)
}
}
return(x)
}
peirce_dev <- function(N, n, m){
# N :: total number of observations
# n :: number of outliers to be removed
# m :: number of model unknowns (e.g., regression parameters)
#
# Check number of observations:
if (N > 1) {
# Calculate Q (Nth root of Gould's equation B):
Q = (n^(n/N) * (N-n)^((N-n)/N))/N
#
# Initialize R values:
Rnew = 1.0
Rold = 0.0  # <- Necessary to prompt while loop
#
while(abs(Rnew-Rold) > (N*2.0e-16)){
# Calculate Lamda (1/(N-n)th root of Gould's equation A'):
ldiv = Rnew^n
if (ldiv == 0){
ldiv = 1.0e-6
}
Lamda = ((Q^N)/(ldiv))^(1.0/(N-n))
#
# Calculate x-squared (Gould's equation C):
x2 = 1.0 + (N-m-n)/n * (1.0-Lamda^2.0)
#
# If x2 goes negative, set equal to zero:
if (x2 < 0){
x2 = 0
Rold = Rnew
} else {
#
# Use x-squared to update R (Gould's equation D):
# NOTE: error function (erfc) is replaced with pnorm (Rbasic):
# source:
# http://stat.ethz.ch/R-manual/R-patched/library/stats/html/Normal.html
Rold = Rnew
Rnew = exp((x2-1)/2.0)*(2*pnorm(sqrt(x2)/sqrt(2)*sqrt(2), lower=FALSE))
}
}
} else {
x2 = 0
}
x2
}
## Rohdatensichtung
```{r include=FALSE}
7.6/.44
7.6/.44
```{r include=FALSE}
raw <- read_excel("~/Desktop/FATL/s.c./lvtemporary_427616.xlsx")
(raw)
n<-c(raw$`% - Rührer [1/min] / 10`)
raw <- read_excel("~/Desktop/FATL/s.c./lvtemporary_427616.xlsx")
## Hefetrockenmassebestimmung mit dem Feuchtegehaltsbestimmer sowie im Trockenschrank und Untersuchung der optischen Dichte
### Aufarbeitung der Rohdaten
```{r include=FALSE}
ODS<-c(1.23,2.4,3.43,4.79,6.7,9.28,10.3,10.98,12.98,14.54) # Optische Dichte der Standardreihe
(CS<-seq( 0.001 , .01 , .001 )) # Vektor der OD-Variation der Standardreihe
ODFerm<-c(33.8,35.2,37.8,39,43,52.5,51) # Vektor beschreibt die OD im Bioreaktor während der Kultivierung
HTS<-c(19.05,13.86,20.8,22.13,23,23.47,23.4) # Hefetrockensubstanz aus der Messung mit dem Feuchtegehaltsbestimmer
HSTT<-c(.2034,.1386,.2344,.2159,.2835,.3835,.2645) #Hefetrockensubstanz aus der Messung mit dem Trockenschrank
TFer<-seq(0,180,30) # Kultivierungszeit
HTTL<-(HSTT*100) # Umrechnung der HSTT in g/L
HTSG<-((HTTL+HTS)/2)
tibble(ODS,CS)
ZSM<-(tibble( n=seq(1,7,1) , "OD während Fermentation" = ODFerm , "HTS Feuchtegehaltsbestimmer in g/l"=HTS,"Gemessene HTS (Trockenschrank)"=HSTT, "HTS in g/l (Trockenschrank)"= HTTL, "Gemittelte HTS"=HTSG))
LGOD<-lm(ODS~CS) # Lineare Regression der Kalibrationsreihe
summary(LGOD)
A<-summary(LGOD)
```
### OD-Eichelgerade
```{r include=FALSE}
ggplot(mapping = aes(CS,ODS))+
geom_point()+
geom_smooth( method="lm" )
CLGOD<-function(OD){ A$coefficients[1,2]+ OD * -A$coefficients[1,1]} # Funktion zur Berechnung der Konzentration mit Hilfe der linearen Regression
ODFerm<-c(33.8,35.2,37.8,39,43,52.5,51) # Vektor beschreibt die zu verschieden ODS in Abhängigkeit der Zeit
Hefekonzentration<-CLGOD(ODFerm) # Berechnung der Hefekonzentration
CLGOD<-function(OD){ A$coefficients[1,2]+ OD * -A$coefficients[1,1]} # Funktion zur Berechnung der Konzentration mit Hilfe der linearen Regression
ODFerm<-c(33.8,35.2,37.8,39,43,52.5,51) # Vektor beschreibt die zu verschieden ODS in Abhängigkeit der Zeit
Hefekonzentration<-CLGOD(ODFerm) # Berechnung der Hefekonzentration
```{r echo=FALSE}
pander(tibble( "Probennnahmezeitpunkt"=TFer , "Gemessene OD"=ODFerm , Hefekonzentration)) # Kabeln des Dataframe
kable::kable(tibble( "Probennnahmezeitpunkt"=TFer , "Gemessene OD"=ODFerm , Hefekonzentration))
install.packages("kableExtra")
kableExtra::kable(tibble( "Probennnahmezeitpunkt"=TFer , "Gemessene OD"=ODFerm , Hefekonzentration))
kableExtra::kable(tibble( "Probennnahmezeitpunkt"=TFer , "Gemessene OD"=ODFerm , Hefekonzentration))
pander(tibble( "Probennnahmezeitpunkt"=TFer , "Gemessene OD"=ODFerm , Hefekonzentration)) # Kabeln des Dataframe
xtable::autoformat(tibble( "Probennnahmezeitpunkt"=TFer , "Gemessene OD"=ODFerm , Hefekonzentration))
xtable::xtable(tibble( "Probennnahmezeitpunkt"=TFer , "Gemessene OD"=ODFerm , Hefekonzentration))
setwd(here::here())
pacman::p_load(tidyverse,plotrix,grid,gridExtra,car,
ggsci,ggsignif, ggthemes, ggridges,
survival, survminer,
ggdendro, rpart,rpart.plot)
#sample data
head(diamonds)
head(mtcars)
ggplot(data=diamonds,aes(x=clarity))+
geom_bar()
#define aesthetics
ggplot(data=diamonds,aes(x=clarity,fill=cut))+
geom_bar()
#aesthetics outside aes
ggplot(data=diamonds,aes(x=clarity))+
geom_bar(fill='gold')
pacman::p_load(tidyverse,plotrix,grid,gridExtra,car,
ggsci,ggsignif, ggthemes, ggridges,
survival, survminer,
ggdendro, rpart,rpart.plot)
install.packages("pacman")
pacman::p_load(tidyverse,plotrix,grid,gridExtra,car,
ggsci,ggsignif, ggthemes, ggridges,
survival, survminer,
ggdendro, rpart,rpart.plot)
#sample data
head(diamonds)
head(mtcars)
ggplot(data=diamonds,aes(x=clarity))+
geom_bar()
#define aesthetics
ggplot(data=diamonds,aes(x=clarity,fill=cut))+
geom_bar()
#aesthetics outside aes
ggplot(data=diamonds,aes(x=clarity))+
geom_bar(fill='gold')
ggplot(data=diamonds,aes(x=clarity))+
geom_bar(aes(fill='gold')) #should be outside aes!
#fill/color
ggplot(data=diamonds,aes(x=clarity,color=cut))+
geom_bar()
ggplot(data=mtcars,aes(factor(cyl),fill=factor(cyl)))+
geom_bar(color='black')
ggplot(data=mtcars,aes(factor(cyl),color=factor(cyl)))+
geom_bar()
help(points)
#other color systems
(plottemp <- ggplot(data=diamonds,aes(x=clarity,fill=cut))+
geom_bar())
plottemp + scale_fill_brewer(palette='Set2') #in-built
plottemp + scale_fill_grey(name = "cut of\ndiamonds")
plottemp + scale_fill_grey(name = "cut of\ndiamonds") + theme_bw()
# ggsci ####
plottemp+scale_fill_lancet()
plottemp+scale_fill_jama()
plottemp+scale_fill_startrek()
#save ggplots
ggsave('ggtestplot.png',width=20,height=20,
units='cm',dpi=150)
#other geoms
ggplot(data=mtcars,aes(x = wt,y = mpg))+
geom_point() #default 1.5 IQR
ggplot(mtcars,aes(x = factor(gear),y = wt))+
geom_boxplot()
ggplot(mtcars,aes(x = factor(gear),y = wt))+
geom_boxplot(coef=3)
ggplot(mtcars,aes(x = factor(gear),y = wt,fill=factor(cyl)))+
geom_boxplot(coef=3)
ggplot(mtcars,aes(x = factor(gear),y = wt))+
geom_boxplot(coef=3)+
geom_point()
ggplot(mtcars,aes(x = factor(gear),y = wt))+
geom_boxplot(coef=3)+
geom_point(position = position_jitter(width = .1))
ggplot(mtcars,aes(x = factor(gear),y = wt))+
geom_boxplot(coef=3)+
geom_dotplot(alpha=.7,
binaxis = 'y',stackdir = 'center',
stackratio = .7,dotsize = .6)
#aesthetics again (finetuning)
ggplot(data=mtcars,aes(wt, mpg,color=qsec))+
geom_point(size=4) #outside aes!
ggplot(data=mtcars,aes(wt, mpg,color=qsec, size=carb))+
geom_point()
ggplot(data=mtcars,aes(wt, mpg,color=qsec, size=carb))+
scale_color_gradient(low='darkred',high='blue')+
geom_point()
ggplot(data=mtcars,aes(wt, mpg,color=qsec, size=carb))+
scale_color_gradient2(low='red',high='yellow',
mid='blue',
limits=c(13,23),midpoint=18)+
geom_point()
# use different aesthetic mappings
ggplot(data=mtcars,
aes(wt, mpg,size=qsec, shape=factor(cyl)))+
geom_point()
ggplot(data=mtcars,aes(carb, mpg,color=qsec, size=wt))+
geom_point(shape=2)
#location, location,position
p<-ggplot(data=diamonds,aes(clarity,fill=cut))
p+geom_bar(position="stack")
p+geom_bar(position="dodge")
p+geom_bar(position="fill")
p+geom_bar(position="fill")+
scale_y_continuous('Frequency (%)',
breaks=seq(0,1,.2),
labels=seq(0,100,20))
p+geom_bar(position="identity")
p+geom_bar(position="identity",alpha=.5)
ggplot(data=diamonds,aes(clarity,color=cut, group=cut))+
geom_freqpoly(stat='count',position="identity",lwd=1.5)+
geom_point(stat='count',size=5)
#layer/order / computed geoms
ggplot(data=mtcars,aes(wt, mpg))+
geom_point(size=4)+
geom_smooth(size=3)
ggplot(data=mtcars,aes(wt, mpg))+
geom_smooth(size=3)+
geom_point(size=4)
ggplot(data=mtcars,aes(wt, mpg))+
geom_smooth(size=3,color='red')+
geom_smooth(method='lm',size=3)+
geom_point(size=4)
ggplot(data=mtcars,aes(wt, mpg,color=factor(cyl)))+
geom_point(size=4)+
geom_smooth(method='lm',size=1)
ggplot(data=mtcars,aes(wt, mpg,color=factor(cyl),
shape=factor(am)))+
geom_point(size=2)+
geom_smooth(method='lm',size=1,se=F)
#? lm for all?
ggplot(data=mtcars,aes(wt, mpg))+
geom_smooth(size=1,color='black',fill='yellow')+
geom_point(size=3,aes(color=factor(cyl),shape=factor(am))) #aes for geom only
# facet_wrap / facet_grid
(p.tmp <- ggplot(mtcars, aes(mpg, wt)) + geom_point())
p.tmp + facet_wrap(~cyl)
p.tmp + facet_wrap(~cyl, ncol=2)
p.tmp + facet_grid(gear~cyl,labeller=label_both,margins='gear')
p.tmp + geom_smooth()+
facet_grid(gear~cyl, labeller=label_both,margins=T)
View(Spinat1)
install.packages("keras")
library(keras)
library(keras)
model.1 keras_model_sequential()
model.1 <- keras_model_sequential()
install_tensorflow()
install.packages("tensorflow")
library(keras)
model.1 <- keras_model_sequential()
library(tensorflow)
model.1 <- keras_model_sequential()
model1 <- keras_model_sequential()
model1 <- keras_model_sequential()
library(keras)
model1 <- keras_model_sequential()
install.packages("keras")
library(keras)
model1 <- keras_model_sequential()
install_tensorflow()
library(tensorflow)
install_tensorflow()
library(keras)
model1 <- keras_model_sequential()
model1 %>%
# wir fügen einen Layer (densley connected) mit 64 units an
layer_dense(units = 64, activation = "relu") %>%
# und noch einen Layer mit 64 units
layer_dense(units = 64, activation = "relu") %>%
# und einen Output-softmax
layer_dense(units = 10, activation = "softmax")
model.1 <- keras_model_sequential()
model.1 %>%
# wir fügen einen Layer (densley connected) mit 64 units an
layer_dense(units = 64, activation = "relu") %>%
# und noch einen Layer mit 64 units
layer_dense(units = 64, activation = "relu") %>%
# und einen Output-softmax
layer_dense(units = 10, activation = "softmax")
data.1 <- matrix(
rnorm(1000 * 32),
nrow = 1000,
ncol = 32
)
labels.1 <- matrix(rnorm(1000, 10),
nrow = 1000,
ncol = 10)
labels.1 <- matrix(rnorm(1000, 10),
nrow = 1000,
ncol = 10)
data.1 <-
matrix(
rnorm(1000 * 32),
nrow = 1000,
ncol = 32
)
data.1 <-matrix(
rnorm(1000 * 32),
nrow = 1000,
ncol = 32
)
data.1 <-
matrix(
rnorm(1000 * 32),
nrow = 1000,
ncol = 32
)
data.1 <-
matrix(
rnorm(1000 * 32),
nrow = 1000,
ncol = 32
)
labels.1 <-
matrix(
rnorm(1000, 10),
nrow = 1000,
ncol = 10)
val.dat <-
matrix(
rnorm(1000, 32),
nrow = 100,
ncol = 32
)
val_data <- matrix(rnorm(1000 * 32), nrow = 100, ncol = 32)
val_labels <- matrix(rnorm(100 * 10), nrow = 100, ncol = 10)
val_data <-
matrix(
rnorm(1000 * 32),
nrow = 100,
ncol = 32)
val_labels <-
matrix(
rnorm(100 * 10),
nrow = 100,
ncol = 10)
model.1
model.1 %>%
fit(
data.1,
labels.1,
epochs = 10,
batch_size = 32,
validation_data = list( val_data,
val_labels)
)
model %>% compile(
optimizer = 'adam',
loss = 'mse',           # mean squared error
metrics = list('mae')   # mean absolute error
)
model %>% compile(
optimizer = 'adam',
loss = 'categorical_crossentropy',
metrics = list('accuracy')
)
# Create a sigmoid layer:
layer_dense(units = 64, activation ='sigmoid')
# A linear layer with L1 regularization of factor 0.01 applied to the kernel matrix:
layer_dense(units = 64, kernel_regularizer = regularizer_l1(0.01))
# A linear layer with L2 regularization of factor 0.01 applied to the bias vector:
layer_dense(units = 64, bias_regularizer = regularizer_l2(0.01))
# A linear layer with a kernel initialized to a random orthogonal matrix:
layer_dense(units = 64, kernel_initializer = 'orthogonal')
# A linear layer with a bias vector initialized to 2.0:
layer_dense(units = 64, bias_initializer = initializer_constant(2.0))
model %>% compile(
optimizer = 'adam',
loss = 'categorical_crossentropy',
metrics = list('accuracy')
)
model %>% compile(
optimizer = 'adam',
loss = 'mse',           # mean squared error
metrics = list('mae')   # mean absolute error
)
library(keras)
model.1 <- keras_model_sequential()
model.1 %>%
# wir fügen einen Layer (densley connected) mit 64 units an
layer_dense(units = 64, activation = "relu") %>%
# und noch einen Layer mit 64 units
layer_dense(units = 64, activation = "relu") %>%
# und einen Output-softmax
layer_dense(units = 10, activation = "softmax")
data.1 <-
matrix(
rnorm(1000 * 32),
nrow = 1000,
ncol = 32
)
labels.1 <-
matrix(
rnorm(1000, 10),
nrow = 1000,
ncol = 10)
val_data <-
matrix(
rnorm(1000 * 32),
nrow = 100,
ncol = 32)
val_labels <-
matrix(
rnorm(100 * 10),
nrow = 100,
ncol = 10)
model.1 %>%
fit(
data.1,
labels.1,
epochs = 10,
batch_size = 32,
validation_data = list( val_data,
val_labels)
)
# use prior analysis as source
source('HSA.R')
library(readr)
# load the complete dataset
# use prior analysis as source
source('HSA.R')
library(readr)
# load the complete dataset
library(readxl)
HSA_Arno <- read_excel("Bachelor/Beispielauswertungen/HSA_Assay/HSA_Arno.xlsx",
sheet = "Tabelle2", col_types = c("skip",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric"))
View(HSA_Arno)
plot(HSA_Arno)
HSA_Arno <- read_excel("Bachelor/Beispielauswertungen/HSA_Assay/HSA_Arno.xlsx",
sheet = "Tabelle2", col_types = c("char",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric"))
HSA_Arno <- read_excel("Bachelor/Beispielauswertungen/HSA_Assay/HSA_Arno.xlsx",
sheet = "Tabelle2", col_types = c("char",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric"))
HSA_Arno <- read_excel("Bachelor/Beispielauswertungen/HSA_Assay/HSA_Arno.xlsx",
sheet = "Tabelle2", col_types = c("character",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric",
"numeric", "numeric", "numeric"))
character()
HSA_Arno <- read_excel("Bachelor/Beispielauswertungen/HSA_Assay/HSA_Arno.xlsx",
sheet = "Tabelle2")
HSA_Arno <- read_excel("Bachelor/Beispielauswertungen/HSA_Assay/HSA_Arno.xlsx",
sheet = "Tabelle2")
View(HSA_Arno)
as.array(HSA_Arno)
HSA_Arno <- read_excel("Bachelor/Beispielauswertungen/HSA_Assay/HSA_Arno.xlsx",
sheet = "Tabelle2", skip = 1)
View(HSA_Arno)
as.array(HSA_Arno)
HSA_Arno <- read_excel("Bachelor/Beispielauswertungen/HSA_Assay/HSA_Arno.xlsx",
sheet = "Tabelle2")
View(HSA_Arno)
as.array(HSA_Arno)
p <- ggplot(mtcars, aes(wt, mpg))
p + stat_identity()
p <- ggplot(mtcars, aes(wt, mpg))
library(tidyverse)
p <- ggplot(mtcars, aes(wt, mpg))
p + stat_identity()
install.packages("units")
devtools::install_github("https://github.com/Utzi1/Biotech")
install.packages("githubinstall")
githubinstall::gh_install_packages("Biotech")
githubinstall::githubinstall("Biotech")
devtools::install_github("https://github.com/Utzi1/Biotech")
devtools::install_github("https://github.com/Utzi1/Biotech")
path.package("purrr")
path.package("purrr")
library(purrr)
path.package("purrr")
setwd("Bachelor/Biotech/R/")
library(devtools)
check()
install.packages("sloop")
install.packages("sloop")
unclass(Biotech::c.any())
unclass(Biotech::c.any(ds = 1, ele = 1, org = 1))
